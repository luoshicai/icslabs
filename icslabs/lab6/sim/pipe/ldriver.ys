#######################################################################
# Test for copying block of size 63;
#######################################################################
	.pos 0
main:	irmovq Stack, %rsp  	# Set up stack pointer

	# Set up arguments for copy function and then invoke it
	irmovq $63, %rdx		# src and dst have 63 elements
	irmovq dest, %rsi	# dst array
	irmovq src, %rdi	# src array
	call ncopy		 
	halt			# should halt with num nonzeros in %rax
StartFun:
#/* $begin ncopy-ys */
##################################################################
# ncopy.ys - Copy a src block of len words to dst.
# Return the number of positive words (>0) contained in src.
#
# Include your name and ID here.
# name :Luo Shicai  ID:520021910605
# Describe how and why you modified the baseline code.
# 1.use iaddq to avoid assigning values every time you use constants. 15.18->12.70
# 2.iaddq $-1,%rdx   andq %rdx,%rdx synthesize one  12.70->11.70
# 3.Loop expansion    11.70->7.93
# 4.Use forwarding to eliminate the stall or bubble between mrmovq and rmmovq 7.93->7.89
# 5.When len<=8 use jumpTable  7.89->7.56 
##################################################################
# Do not modify this portion
# Function prologue.
# %rdi = src, %rsi = dst, %rdx = len
ncopy:

##################################################################
# You can modify this portion
	# Loop headeri
        iaddq $-10,%rdx
        jle break           #len>10?
#len>10
handler1:
        mrmovq (%rdi),%r8
        rmmovq %r8,(%rsi)
        andq %r8,%r8
        mrmovq 8(%rdi),%r9
        rmmovq %r9,8(%rsi)
        jle judge1
        iaddq $1,%rax
judge1:
        andq %r9,%r9
        mrmovq 16(%rdi),%r10
        rmmovq %r10,16(%rsi)
        jle judge2
        iaddq $1,%rax
judge2:
        andq %r10,%r10
        mrmovq 24(%rdi),%r11
        rmmovq %r11,24(%rsi)        
        jle judge3
        iaddq $1,%rax
judge3:
        andq %r11,%r11
        mrmovq 32(%rdi),%r12
        rmmovq %r12,32(%rsi)
        jle judge4
        iaddq $1,%rax
judge4:
        andq %r12,%r12
        mrmovq 40(%rdi),%r13
        rmmovq %r13,40(%rsi)
        jle judge5
        iaddq $1,%rax
judge5:
        andq %r13,%r13
        mrmovq 48(%rdi),%r14
        rmmovq %r14,48(%rsi)
        jle judge6
        iaddq $1,%rax
judge6:
        andq %r14,%r14
        mrmovq 56(%rdi),%rcx
        rmmovq %rcx,56(%rsi)
        jle judge7
        iaddq $1,%rax
judge7:
        andq %rcx,%rcx
        mrmovq 64(%rdi),%r8
        rmmovq %r8,64(%rsi)
        jle judge8 
        iaddq $1,%rax
judge8:
        andq %r8,%r8
        mrmovq 72(%rdi),%r10
        rmmovq %r10,72(%rsi)
        jle judge9
        iaddq $1,%rax
judge9:
        andq %r10,%r10
        jle judgeEnd1
        iaddq $1,%rax
judgeEnd1:
        iaddq $80,%rdi
        iaddq $80,%rsi
        iaddq $-10,%rdx
        jg handler1

break:
        addq %rdx,%rdx
        addq %rdx,%rdx
        addq %rdx,%rdx
        mrmovq Jump(%rdx),%r9
        pushq %r9
        ret

last10:
        mrmovq 72(%rdi),%r8
        rmmovq %r8,72(%rsi)
        addq %r8,%r8
        jle last9
        iaddq $1,%rax
last9:
        mrmovq 64(%rdi),%r8
        rmmovq %r8,64(%rsi)
        addq %r8,%r8
        jle last8
        iaddq $1,%rax
last8:
        mrmovq 56(%rdi),%r8
        rmmovq %r8,56(%rsi)
        andq %r8,%r8
        jle last7
        iaddq $1,%rax
last7:
        mrmovq 48(%rdi),%r8
        rmmovq %r8,48(%rsi)
        andq %r8,%r8
        jle last6
        iaddq $1,%rax
last6:
        mrmovq 40(%rdi),%r8
        rmmovq %r8,40(%rsi)
        andq %r8,%r8
        jle last5
        iaddq $1,%rax
last5:
        mrmovq 32(%rdi),%r8
        rmmovq %r8,32(%rsi)
        andq %r8,%r8
        jle last4
        iaddq $1,%rax
last4:
        mrmovq 24(%rdi),%r8
        rmmovq %r8,24(%rsi)
        andq %r8,%r8
        jle last3
        iaddq $1,%rax
last3:
        mrmovq 16(%rdi),%r8
        rmmovq %r8,16(%rsi)
        andq %r8,%r8
        jle last2
        iaddq $1,%rax
last2:
        mrmovq 8(%rdi),%r8
        rmmovq %r8,8(%rsi)
        andq %r8,%r8
        jle last1
        iaddq $1,%rax
last1:
        mrmovq (%rdi),%r8
        rmmovq %r8,(%rsi)
        andq %r8,%r8
        jle Done
        iaddq $1,%rax
last0:
        ret

JumpTable:
    .quad last0
    .quad last1
    .quad last2
    .quad last3
    .quad last4
    .quad last5
    .quad last6
    .quad last7
    .quad last8
    .quad last9
Jump:
    .quad last10
##################################################################
# Do not modify the following section of code
# Function epilogue.
Done:
	ret
##################################################################
# Keep the following label at the end of your function
End:
#/* $end ncopy-ys */
EndFun:

###############################
# Source and destination blocks 
###############################
	.align 8
src:
	.quad -1
	.quad 2
	.quad -3
	.quad 4
	.quad 5
	.quad 6
	.quad 7
	.quad 8
	.quad 9
	.quad -10
	.quad 11
	.quad 12
	.quad -13
	.quad 14
	.quad -15
	.quad -16
	.quad 17
	.quad -18
	.quad -19
	.quad 20
	.quad 21
	.quad -22
	.quad 23
	.quad -24
	.quad -25
	.quad 26
	.quad -27
	.quad -28
	.quad -29
	.quad 30
	.quad -31
	.quad 32
	.quad 33
	.quad 34
	.quad 35
	.quad 36
	.quad 37
	.quad -38
	.quad 39
	.quad -40
	.quad 41
	.quad 42
	.quad 43
	.quad 44
	.quad 45
	.quad -46
	.quad -47
	.quad -48
	.quad 49
	.quad 50
	.quad 51
	.quad -52
	.quad -53
	.quad -54
	.quad -55
	.quad -56
	.quad -57
	.quad -58
	.quad -59
	.quad -60
	.quad -61
	.quad -62
	.quad -63
	.quad 0xbcdefa # This shouldn't get moved

	.align 16
Predest:
	.quad 0xbcdefa
dest:
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
Postdest:
	.quad 0xdefabc

.align 8
# Run time stack
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0

Stack:
